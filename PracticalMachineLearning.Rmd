---
title: "PracticalMachineLearning"
author: "Sylas"
date: "16 July 2017"
output:
  md_document: default
  keep_md: yes
---

```{r setup, include=FALSE}
library(ROCR)
library(randomForest)
library(caret)
```

#PRACTICAL MACHINE LEARNING
#### Loading the data and creating the pairs plot for the classifier to be used to go through the visual representation of the classifier i am going to use.To predict the classes of output from the human recognition data. Th class value reprsent, class-A throws elbows to the front,Class-B lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).To predict the class value identified the releveant classifier and created the formula to pass in the random forest algorithm. 

```{r train and test,include=TRUE}
setwd("C:/Coursera/Practical Machine Learning")
train <- read.csv("pml-training.csv",header=T,stringsAsFactors=T, sep=",")
test <- read.csv("pml-testing.csv",header=T,stringsAsFactors=T, sep=",")
pairs(classe ~ roll_belt+pitch_belt+yaw_belt+total_accel_arm+roll_dumbbell+pitch_dumbbell+yaw_dumbbell+total_accel_forearm,data=train)
classif <- formula(classe  ~ roll_belt+pitch_belt+yaw_belt+total_accel_arm+roll_dumbbell+pitch_dumbbell+yaw_dumbbell+roll_arm+pitch_arm+magnet_dumbbell_x+magnet_dumbbell_y+magnet_dumbbell_z+roll_forearm+pitch_forearm+yaw_forearm+total_accel_forearm)
model <-randomForest(classif,data=train,importance=TRUE)
importance(model)
print(model)

test_predict <- predict (model,test)

```
##### The above summary of results says about the predicted value and the error rate in the confusion matrix.Also the out of sample error rate of 0.53% if we consider the all the training data to construct the model.



## CROSS VALIDATION ALGORITHM
#### Used the 3 cross validation to verify the out of sample error and applied the predicted value to the test data.

```{r pressure, echo=TRUE}
first_seed <- 1234
accuracies <-c()
for (i in 1:3){
       set.seed(first_seed)
       first_seed <- first_seed+1
       trainIndex <- createDataPartition(y=train$classe, p=0.75, list=FALSE)
       trainingSet<- train[trainIndex,]
       testingSet<- train[-trainIndex,]
       modelFit <- randomForest(classif, data = trainingSet,importance=TRUE)
       prediction <- predict(modelFit, testingSet)
       testingSet$rightPred <- prediction == testingSet$classe
       t<-table(prediction, testingSet$classe)
       print(modelFit)
       accuracy <- sum(testingSet$rightPred)/nrow(testingSet)
       accuracies <- c(accuracies,accuracy)
       print(accuracy)
}
predict_test <- predict (modelFit,test)
predict_test

```
#### In the above method of cross validation sample the out of bag error is in the range of 0.75 and it is very close to the full model OOB error, also the accuracy rate comingout of the cross validation method random forest application is in the good mark.This model is not overfitted it produce the accurate results in the test data prediction.
